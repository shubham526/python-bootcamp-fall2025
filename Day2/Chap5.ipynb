{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Notebook 6: Data Manipulation with Pandas\n",
    "\n",
    "Welcome to data manipulation with **Pandas**! While NumPy is excellent for working with clean, numerical arrays, real-world data is often messy, labeled, and contains missing values. Pandas is the essential tool for cleaning, transforming, and analyzing this kind of data.\n",
    "\n",
    "**Session Goals:**\n",
    "* Understand the core Pandas data structures: the **`Series`**, **`DataFrame`**, and **`Index`**.\n",
    "* Learn to select, filter, and manipulate data within these structures.\n",
    "* Perform powerful grouping and aggregation operations to summarize data.\n",
    "* Use pivot tables to create multidimensional data summaries."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "--- \n",
    "## Part 1: Introducing Pandas Objects\n",
    "\n",
    "At its core, Pandas provides two primary data structures that build upon NumPy arrays but add labels for rows and columns, providing much more flexibility."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Setup: Importing Pandas\n",
    "\n",
    "Just as we import NumPy with the alias `np`, the standard convention is to import Pandas with the alias `pd`. We'll use this throughout the notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The Pandas `Series` Object\n",
    "\n",
    "A Pandas `Series` is a one-dimensional array of indexed data. It's like a NumPy array but with an explicit index that can be used to label the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating a Series from a list\n",
    "data = pd.Series([0.25, 0.5, 0.75, 1.0])\n",
    "print(\"A basic Series:\")\n",
    "print(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A `Series` object wraps both a sequence of values and a sequence of indices. We can access these with the `values` and `index` attributes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The values are a NumPy array\n",
    "print(\"Values:\", data.values)\n",
    "\n",
    "# The index is an array-like object\n",
    "print(\"Index:\", data.index)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The key difference from a NumPy array is the explicit index. This index doesn't have to be an integer; it can be strings or any other desired type."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating a Series with a string index\n",
    "data = pd.Series([0.25, 0.5, 0.75, 1.0],\n",
    "                 index=['a', 'b', 'c', 'd'])\n",
    "print(data)\n",
    "\n",
    "# You can now access items using this custom index\n",
    "print(\"\\nValue at index 'b':\", data['b'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can also think of a `Series` as a specialized Python dictionary, where it maps typed keys (the index) to a set of typed values. You can even create a `Series` directly from a dictionary."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "population_dict = {'California': 38332521,\n",
    "                   'Texas': 26448193,\n",
    "                   'New York': 19651127,\n",
    "                   'Florida': 19552860,\n",
    "                   'Illinois': 12882135}\n",
    "population = pd.Series(population_dict)\n",
    "print(population)\n",
    "\n",
    "# You can still use dictionary-style item access\n",
    "print(\"\\nPopulation of California:\", population['California'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### ✏️ Try It Yourself: Series Creation\n",
    "\n",
    "Create a `Series` object named `my_series` that stores the heights (in cm) of three people. Use their names as the index.\n",
    "\n",
    "* 'Alice': 165\n",
    "* 'Bob': 180\n",
    "* 'Charlie': 175\n",
    "\n",
    "Then, print the `Series` and access Bob's height using his name as the index."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Write your code here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The Pandas `DataFrame` Object\n",
    "\n",
    "A `DataFrame` is the next fundamental structure in Pandas. If a `Series` is a one-dimensional array with flexible indices, a `DataFrame` is a two-dimensional array with both flexible row indices and flexible column names. You can think of it as a sequence of aligned `Series` objects that share the same index."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "area_dict = {'California': 423967, 'Texas': 695662, 'New York': 141297,\n",
    "             'Florida': 170312, 'Illinois': 149995}\n",
    "area = pd.Series(area_dict)\n",
    "\n",
    "# Create a DataFrame from two Series objects\n",
    "states = pd.DataFrame({'population': population, 'area': area})\n",
    "print(states)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Like a `Series`, a `DataFrame` has an `index` attribute. It also has a `columns` attribute that holds the column labels."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"DataFrame Index:\", states.index)\n",
    "print(\"DataFrame Columns:\", states.columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can also think of a `DataFrame` as a dictionary where column names map to `Series` objects. This means you can access a column using dictionary-style indexing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Accessing the 'area' column returns a Series object\n",
    "print(states['area'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### ✏️ Try It Yourself: DataFrame Creation\n",
    "\n",
    "Create a `DataFrame` named `city_data` with information about three cities.\n",
    "\n",
    "1.  Create two `Series` objects:\n",
    "    * `population` with index `['Tokyo', 'Delhi', 'Shanghai']` and corresponding values `[37.4, 29.4, 26.3]` (in millions).\n",
    "    * `country` with the same index and values `['Japan', 'India', 'China']`.\n",
    "2.  Combine these two `Series` into a `DataFrame`.\n",
    "3.  Print the `DataFrame`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Write your code here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "--- \n",
    "## Part 2: Data Indexing and Selection\n",
    "\n",
    "Pandas offers powerful ways to access and modify data in `Series` and `DataFrame` objects, similar to NumPy but with some important differences."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Selection in `Series`\n",
    "\n",
    "A `Series` acts like both a dictionary and a NumPy array, giving you multiple ways to select data.\n",
    "\n",
    "#### `loc` and `iloc`\n",
    "To avoid confusion, especially with integer indexes, Pandas provides two special indexer attributes:\n",
    "* **`.loc`**: Always references the **explicit** index (the labels). When slicing with `.loc`, the final index is **included**.\n",
    "* **`.iloc`**: Always references the **implicit**, Python-style integer index (position). When slicing with `.iloc`, the final index is **excluded**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.Series(['a', 'b', 'c'], index=[1, 3, 5])\n",
    "print(\"Original Series:\")\n",
    "print(data)\n",
    "\n",
    "# Using .loc (explicit index)\n",
    "print(\"\\nloc[1]:\", data.loc[1])\n",
    "print(\"\\nloc[1:3]:\")\n",
    "print(data.loc[1:3]) # Includes index 3\n",
    "\n",
    "# Using .iloc (implicit index)\n",
    "print(\"\\niloc[1]:\", data.iloc[1])\n",
    "print(\"\\niloc[1:3]:\")\n",
    "print(data.iloc[1:3]) # Excludes index 3 (position 3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Selection in `DataFrame`\n",
    "\n",
    "A `DataFrame` also acts like a dictionary of columns and a 2D array of rows.\n",
    "\n",
    "* **Dictionary-style indexing** `df['col']` selects a column.\n",
    "* **Array-style indexing** using `.loc` and `.iloc` selects rows and columns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Original states DataFrame:\")\n",
    "print(states)\n",
    "\n",
    "# Selecting rows with iloc (implicit index)\n",
    "print(\"\\nFirst two rows with iloc[:2, :]:\")\n",
    "print(states.iloc[:2, :])\n",
    "\n",
    "# Selecting rows with loc (explicit index)\n",
    "print(\"\\nRows from California to Illinois with loc:\")\n",
    "print(states.loc['California':'Illinois', :])\n",
    "\n",
    "# Combining row and column selection\n",
    "print(\"\\nPopulation column for Texas with loc:\")\n",
    "print(states.loc['Texas', 'population'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Filtering and Masking\n",
    "You can use boolean conditions to filter data, just like in NumPy. This is one of the most powerful features of Pandas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add a 'density' column for our example\n",
    "states['density'] = states['population'] / states['area']\n",
    "print(\"DataFrame with density column:\")\n",
    "print(states)\n",
    "\n",
    "# Use a boolean mask to filter for states with density > 100\n",
    "print(\"\\nStates with density > 100:\")\n",
    "print(states[states['density'] > 100])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### ✏️ Try It Yourself: Selection and Filtering\n",
    "\n",
    "Using the `city_data` DataFrame you created earlier:\n",
    "\n",
    "1.  Select the row for 'Delhi' using `.loc`.\n",
    "2.  Select the first two rows using `.iloc`.\n",
    "3.  Select the `country` column for all rows.\n",
    "4.  Filter the DataFrame to show only cities with a population greater than 30 million."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Write your code here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "--- \n",
    "## Part 3: Handling Missing Data\n",
    "\n",
    "Real-world data is rarely clean and often has missing values. Pandas represents missing numerical data with `NaN` (Not a Number) and provides excellent tools for handling it."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pandas provides several useful methods for working with null values:\n",
    "* `isnull()`: Generates a boolean mask indicating missing values.\n",
    "* `notnull()`: The opposite of `isnull()`.\n",
    "* `dropna()`: Returns a filtered version of the data, dropping rows or columns with null values.\n",
    "* `fillna()`: Returns a copy of the data with missing values filled or imputed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame([[1,      np.nan, 2],\n",
    "                   [2,      3,      5],\n",
    "                   [np.nan, 4,      6]])\n",
    "print(\"Original DataFrame with NaN values:\")\n",
    "print(df)\n",
    "\n",
    "# Check for null values\n",
    "print(\"\\nBoolean mask of null values (isnull()):\")\n",
    "print(df.isnull())\n",
    "\n",
    "# Drop rows with any null values\n",
    "print(\"\\nDataFrame after dropping rows with nulls (dropna()):\")\n",
    "print(df.dropna())\n",
    "\n",
    "# Fill null values with a specific value (e.g., 0)\n",
    "print(\"\\nDataFrame after filling nulls with 0 (fillna(0)):\")\n",
    "print(df.fillna(0))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "--- \n",
    "## Part 4: Aggregation and Grouping\n",
    "\n",
    "A crucial piece of data analysis is summarization. This can be a simple aggregation (like `mean()` or `sum()`) or a more complex **`groupby`** operation."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Simple Aggregations\n",
    "For a `DataFrame`, aggregates by default return results within each column. The `.describe()` method is a convenient way to compute several common aggregates for each column and get a quick statistical summary."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rng = np.random.RandomState(42)\n",
    "df = pd.DataFrame({'A': rng.rand(5),\n",
    "                   'B': rng.rand(5)})\n",
    "print(\"Original DataFrame:\")\n",
    "print(df)\n",
    "\n",
    "# Calculate the mean of each column\n",
    "print(\"\\nColumn means:\")\n",
    "print(df.mean())\n",
    "\n",
    "# Get a statistical summary\n",
    "print(\"\\nStatistical summary with describe():\")\n",
    "print(df.describe())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### GroupBy: Split, Apply, Combine\n",
    "\nThe `groupby` operation allows you to compute aggregates on subsets of your data. It follows a three-step process coined by Hadley Wickham: **Split, Apply, Combine**.\n",
    "\n",
    "1.  **Split**: The data is broken up into groups based on the value of a specified key.\n",
    "2.  **Apply**: A function (usually an aggregate like `sum()` or `mean()`) is applied to each individual group.\n",
    "3.  **Combine**: The results of these operations are merged into a new `DataFrame`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame({'key': ['A', 'B', 'C', 'A', 'B', 'C'],\n",
    "                   'data': range(6)}, columns=['key', 'data'])\n",
    "print(\"Original DataFrame:\")\n",
    "print(df)\n",
    "\n",
    "# Group by the 'key' column and then apply the sum() aggregation\n",
    "print(\"\\nSum of data, grouped by key:\")\n",
    "print(df.groupby('key').sum())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### ✏️ Try It Yourself: Grouping\n",
    "\n",
    "Create a `DataFrame` about employees with columns `department`, `name`, and `salary`.\n",
    "\n",
    "```python\n",
    "employee_df = pd.DataFrame({\n",
    "    'department': ['Sales', 'Engineering', 'Sales', 'Engineering', 'HR'],\n",
    "    'name': ['Alice', 'Bob', 'Charlie', 'David', 'Eve'],\n",
    "    'salary': [70000, 80000, 75000, 90000, 65000]\n",
    "})\n",
    "```\n",
    "\n",
    "Use `groupby()` to calculate the **average salary** for each department."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Write your code here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pivot Tables\n",
    "\n",
    "A pivot table is a multidimensional version of a `GroupBy` aggregation. It takes simple column-wise data and groups the entries into a two-dimensional table, providing a multidimensional summary."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the built-in 'titanic' dataset from Seaborn for this example\n",
    "import seaborn as sns\n",
    "titanic = sns.load_dataset('titanic')\n",
    "\n",
    "print(\"A few rows of the Titanic dataset:\")\n",
    "print(titanic.head())\n",
    "\n",
    "# Let's look at the survival rate by sex and class\n",
    "print(\"\\nSurvival rate by sex and class:\")\n",
    "print(titanic.pivot_table('survived', index='sex', columns='class'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "--- \n",
    "## Final Capstone Exercises 📈\n",
    "\n",
    "These final exercises will require you to combine everything you've learned about Pandas to perform a realistic data analysis task."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 0: Create the Dataset\n",
    "\n",
    "Run the cell below to create a sample `sales_data.csv` file. This represents sales records for a small company."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%writefile sales_data.csv\n",
    "Date,Region,Product,Units,Sale\n",
    "2025-01-15,East,Gadget,12,1200\n",
    "2025-01-16,West,Widget,10,1500\n",
    "2025-02-10,East,Gadget,8,800\n",
    "2025-02-11,North,Widget,15,2250\n",
    "2025-03-05,West,Gadget,20,2000\n",
    "2025-03-06,East,Sprocket,5,250\n",
    "2025-04-20,South,Widget,18,2700\n",
    "2025-04-21,North,Sprocket,7,350\n",
    "2025-04-22,West,Widget,10,"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise 1: Basic Sales Data Analysis\n",
    "\n",
    "Your first task is to load the sales data and perform a preliminary analysis.\n",
    "\n",
    "**Requirements:**\n",
    "1.  Load `sales_data.csv` into a Pandas `DataFrame` called `sales_df`.\n",
    "2.  Inspect the data using `.head()` and `.info()`. You should notice there's a missing value in the `Sale` column.\n",
    "3.  Handle the missing data. For this exercise, use `.dropna()` to remove the row with the missing sale amount.\n",
    "4.  Calculate and print the **total sales** for the entire dataset.\n",
    "5.  Find and print the **best-selling product** (in terms of total units sold)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Write your code for Exercise 1 here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise 2: Regional Performance Report\n",
    "\n",
    "Building on your work from Exercise 1, now you need to generate a more detailed report that summarizes performance by region.\n",
    "\n",
    "**Requirements:**\n",
    "1.  Start with your cleaned `sales_df` from the previous exercise.\n",
    "2.  Create a new column called `Price Per Unit` by dividing the `Sale` column by the `Units` column.\n",
    "3.  Using `groupby()`, calculate the **total units sold** and **total sales revenue** for each `Region`.\n",
    "4.  Using a pivot table, find the **average sale amount** for each `Product` in each `Region`.\n",
    "5.  Print both the grouped summary and the pivot table with clear, descriptive headers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Write your code for Exercise 2 here"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}